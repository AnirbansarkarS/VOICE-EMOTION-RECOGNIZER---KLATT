<h1 align="center">ğŸ™ï¸ Voice Emotion Recognition</h1>
<p align="center">
  <img src="https://img.shields.io/badge/Streamlit-Deployed-brightgreen?style=flat-square&logo=streamlit" />
  <img src="https://img.shields.io/github/languages/top/anirbanSarkars/voice-emotion-recognizer?style=flat-square" />
  <img src="https://img.shields.io/badge/Made%20with-%E2%9D%A4%EF%B8%8F%20by%20Anirban-blueviolet?style=flat-square" />
</p>

---

## ğŸ§  What It Does

**Voice Emotion Recognition** is a real-time web application that listens to your voice and **detects your emotion** in seconds â€” powered by machine learning and a minimalistic Streamlit UI.

Whether you're feeling ğŸ‰ happy, ğŸ˜  angry, ğŸ˜¢ sad, or ğŸ˜ neutral â€” the app understands you.

---

## ğŸŒŸ Highlights

ğŸš€ Live voice recording  
ğŸ§ Upload `.wav` files for prediction  
ğŸ¤– ML-powered emotion classification  
ğŸ“Š Visual probability pie chart  
ğŸ¨ Simple, clean UI with one-click predictions

---

## ğŸ“½ Demo Preview

> ğŸ¬ _Coming Soon_: You can host this on [Streamlit Cloud](https://streamlit.io/cloud) for others to try.

---

## ğŸ›  Built With

| Technology       | Role                            |
|------------------|----------------------------------|
| `Python 3.x`     | Core Language                   |
| `Streamlit`      | Web App Framework               |
| `scikit-learn`   | ML Model Training & Inference   |
| `librosa`        | Audio Feature Extraction        |
| `sounddevice`    | Live Audio Recording            |
| `matplotlib`     | Visualization (Pie Chart)       |

---

## ğŸ—‚ Project Structure

voice-emotion-recognizer/
â”‚
â”œâ”€â”€ app.py # Main Streamlit App
â”œâ”€â”€ models/
â”‚ â””â”€â”€ emotion_model.pkl # Pre-trained Emotion Classifier
â”œâ”€â”€ utils/
â”‚ â””â”€â”€ audio_features.py # Feature Extraction Code
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

yaml
Copy
Edit

---

## ğŸ§ª Try It Locally

```bash
git clone https://github.com/anirbanSarkars/voice-emotion-recognizer.git
cd voice-emotion-recognizer

# Create & activate virtual environment
python -m venv emotion_track
emotion_track\Scripts\activate   # On Windows

# Install dependencies
pip install -r requirements.txt

# Run the app
streamlit run app.py
Then open http://localhost:8501 in your browser.

ğŸ“¦ Dependencies
txt
Copy
Edit
streamlit
numpy<=2.2
sounddevice
scikit-learn
librosa
matplotlib
joblib
soundfile
âœ… Note: numpy<=2.2 is required to ensure compatibility with numba.

ğŸ’¡ How It Works
You record or upload an audio file.

The app extracts MFCC features using librosa.

A trained RandomForestClassifier predicts the emotion.

The app visualizes probabilities via a pie chart.

ğŸ“š Dataset
Model trained on the RAVDESS Speech Emotion Dataset, containing emotional speech recordings across multiple speakers.

ğŸ”— Live Hosting Options
Platform	Supports Streamlit
Streamlit Cloud	âœ…
Render	âœ…
GitHub Pages	âŒ (only static sites)

ğŸ™Œ Acknowledgements
This project was built with passion by Anirban Sarkar â€” a curious learner, coder, and innovator dedicated to building intelligent systems that understand human behavior.

ğŸ¤ Contribute
Want to add more emotion categories, retrain the model, or make the UI even cooler?
Fork this repo, build your magic, and make a PR!

ğŸ“œ License
MIT License.
Feel free to use and modify with credit.

ğŸš€ Final Thoughts
"Emotion is energy in motion. Let's help machines understand it too."

If you liked this project â€” drop a â­ on GitHub and share it!
Letâ€™s make emotion recognition more accessible, one voice at a time.
